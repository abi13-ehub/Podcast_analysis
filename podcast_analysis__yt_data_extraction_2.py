# -*- coding: utf-8 -*-
"""Podcast analysis_ YT data extraction-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/abi13-ehub/Podcast_analysis/blob/main/Podcast%20analysis_%20YT%20data%20extraction-2.ipynb

# Data Downloading and compiling
"""

!pip install streamlit==1.24.1

!pip3 install --upgrade google-api-python-client

import googleapiclient
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import emoji
import streamlit as st

from googleapiclient.discovery import build

api_key = 'AIzaSyDTVR2RoWa9PB3uSVkaptspu4XpdxVM25k'
channel_ids = ['UCzQUP1qoWDoEbmsQxvdjxgQ','UCPxMZIFE856tbTfdkdjzTSQ','UCpeRzRS1b1NvY4og1huE7jw','UC2bBsPXFWZWiBmkRiNlz8vg','UCUOjpYruRCB61RnB846trCQ','UCGX7nGXpz-CmO_Arg-cgJ7A','UCSHZKyawb77ixDdsGog4iWA','UCGq-a57w-aPwyi3pW7XLiHw','UCZjxPbi3AeB6YGKCfQ2TroQ','UCKPxuul6zSLAfKSsm123Vww','UCZxgZTreiWF-12p-GS5R7nQ','UC2D2CMWXMOVWx7giW1n3LIg','UCFo9mvW4ythx_tgT3NHaw-Q','UChMV78lIxhu3eqNtPMJGBtA']
youtube = build('youtube','v3',developerKey = api_key)

def get_channel_stats(youtube,channel_id):

    request = youtube.channels().list(part ='snippet, contentDetails, statistics', id = channel_id)
    response = request.execute()
    data = dict(Channel_name = response['items'][0]['snippet']['title'],
                    Subscribers_count = response['items'][0]['statistics']['subscriberCount'],
                    Total_Views_Count= response['items'][0]['statistics']['viewCount'],
                    Total_Videos= response['items'][0]['statistics']['videoCount'],
                    DateStarted= response['items'][0]['snippet']['publishedAt'],
                    playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads'])
    return data

get_channel_stats(youtube, channel_ids[0])

"""pandas.DataFrame.T property is used to transpose the index and columns of the data frame. The property T is somehow related to the method transpose().  The main function of this property is to create a reflection of the data frame over the main diagonal by making rows into columns and vice versa. Sometimes we need to transpose the data frame in order to study it more accurately"""

# Let's put all general statistics in one dataframe.

general_stats = pd.DataFrame()

for i in range(len(channel_ids)):
    data = pd.Series(get_channel_stats(youtube, channel_ids[i])).to_frame().T
    general_stats = pd.concat([general_stats, data], axis=0)

general_stats = general_stats.reset_index(drop=True)

# Preview of general_stats dataframe
general_stats.tail(5)

def get_video_ids(youtube, playlist_id):
    request = youtube.playlistItems().list(part = 'contentDetails',playlistId = playlist_id, maxResults=100)
    response = request.execute()
    videos_id = []
    for i in range(len(response['items'])):
        videos_id.append(response['items'][i]['contentDetails']['videoId'])

    next_page_token = response.get('nextPageToken')
    more_pages = True

    while more_pages:
        if next_page_token is None:
            more_pages = False
        else:
            request = youtube.playlistItems().list(part = 'contentDetails',playlistId = playlist_id, maxResults=100, pageToken = next_page_token)
            response = request.execute()
            for i in range(len(response['items'])):
                videos_id.append(response['items'][i]['contentDetails']['videoId'])

            next_page_token = response.get('nextPageToken')


    return videos_id

# Let's store all video ids, it will be a list of lists that contain video ids for each channel seperately.

video_ids = []

for i in range(len(channel_ids)):
    video_ids.append(get_video_ids(youtube, general_stats.playlist_id.iloc[i]))

"""Now we will get info about the videos and store them in one data frame. We will also add a column called 'identity' in order to distinguish to which channel the video belongs."""

# We got general statistics. Let's get video information now
def get_video_details(youtube, video_ids):
    all_video_stats = []
    for i in range(0,len(video_ids),50):
        request = youtube.videos().list(part = 'snippet,statistics',id =','.join(video_ids[i:i+50])) #limit to requests is 50
        response = request.execute()

        for video in response['items']:
            video_stats = dict(Title = video['snippet']['title'], Publish_Date = video['snippet']['publishedAt'],
                                        Views = video['statistics']['viewCount'], Likes = video['statistics'].get('likeCount',0),
                                        Comments = video['statistics'].get('commentCount',0))
            all_video_stats.append(video_stats)
    return all_video_stats

# Lets check how the function works
video_stats = get_video_details(youtube, video_ids[13])
video_stats = pd.DataFrame(video_stats)
video_stats.head()

video_dfs = []

for i in range(len(channel_ids)):
    df = pd.DataFrame(get_video_details(youtube, video_ids[i]))
    df['Identity'] = general_stats.Channel_name.iloc[i]  # to know to which channel the video belongs.
    video_dfs.append(df)

video_dfs[-1].head()

# Storing all video information dataframes in a list

video_df = pd.DataFrame()
for df in video_dfs:
    video_df = pd.concat([video_df, df], axis = 0)

video_df = video_df.reset_index(drop= True)

video_df.shape

"""So now we got the DataFrames we needed:
general_stats: The channel general statistics.
video_df: a data frame containing all videos of all channels.

# DATA CLEANING
"""

general_stats.sample(4)

video_df.sample(4)

print(video_dfs)

"""Let's start data cleaning with general_stats because its smaller compared to video_df"""

# Check for missing values
general_stats.isnull().sum()

"""No null values sweet. So let's check the data type of the columns"""

general_stats.dtypes

"""We need to change that since Subscribers_Count, Total_Views_Count, and Total_Videos need to be an integer type so we can perform aggregate functions later. Also, the DateStarted needs to be a DateTime datatype."""

general_stats['Subscribers_count'] = pd.to_numeric(general_stats['Subscribers_count'])
general_stats['Total_Views_Count'] = pd.to_numeric(general_stats['Total_Views_Count'])
general_stats['Total_Videos'] = pd.to_numeric(general_stats['Total_Videos'])
general_stats['DateStarted'] = pd.to_datetime(general_stats['DateStarted'], errors ='coerce').dt.floor('d')

general_stats.dtypes

# Lets look at the dataframe now
general_stats.head(5)

# Lets clean video_df now
video_df.isnull().sum()

video_df.dtypes

video_df['Publish_Date'] = pd.to_datetime(video_df['Publish_Date']).dt.date.astype('datetime64')
video_df['Views'] = pd.to_numeric(video_df['Views'])
video_df['Likes'] = pd.to_numeric(video_df['Likes'])
video_df['Comments'] = pd.to_numeric(video_df['Comments'])

video_df.dtypes

video_df.head(10)

"""# EDA"""

pd.set_option('float_format', '{:.1f}'.format)

general_stats.describe()

"""We see that avg number of subscribers is around 24,60,685. And avg total_videos is 10,046 because we have ANI News and JRE which are vast and old. So remove these outliers.

Notice that the Channel_name, DateStarted, and playlist_id are omitted because they are not numeric and we can’t perform aggregate functions on them.
"""

general_stats.shape

"""We have 14 entries in general_stats and each one has 6 attributes

In order to find how many videos we have in total, we can do it in 2 ways:

1. Sum the Total_videos values in the general_stats data frame.

undefined. Check the length of the video_df data frame.
"""

general_stats['Total_Videos'].sum()

"""So up to the day where I ran this code, we have a total of 1,40,683 videos. That is surely going to change if we run this code, let’s say, a month later since the channels will publish more videos in that time period.

## Let's see a distribution plot on the number of subscribers
"""

DeepnoteChart(general_stats, """{"layer":[{"layer":[{"mark":{"clip":true,"type":"area","color":"#4c78a8","tooltip":true},"encoding":{"x":{"sort":null,"type":"nominal","field":"Channel_name","scale":{"type":"linear"},"stack":"zero"},"y":{"sort":null,"type":"quantitative","field":"Subscribers_count","scale":{"type":"linear"},"stack":"zero","format":{"type":"default","decimals":null},"formatType":"numberFormatFromNumberType"}}}]}],"title":"","config":{"legend":{}},"$schema":"https://vega.github.io/schema/vega-lite/v5.json","encoding":{}}""")

"""So we have a plot describing the number of subscribers each channel has, the max is Powerful JRE and the least is Abhinav Prakash.

### Visualize the channels with their starting date.
"""

DeepnoteChart(general_stats, """{"layer":[{"layer":[{"mark":{"clip":true,"type":"trail","color":"#f58518","tooltip":true},"encoding":{"x":{"sort":null,"type":"nominal","field":"Channel_name","scale":{"type":"linear","zero":false}},"y":{"sort":null,"type":"temporal","field":"DateStarted","scale":{"type":"linear","zero":false}}}},{"mark":{"size":100,"type":"point","opacity":0,"tooltip":true},"encoding":{"x":{"sort":null,"type":"nominal","field":"Channel_name","scale":{"type":"linear","zero":false}},"y":{"sort":null,"type":"temporal","field":"DateStarted","scale":{"type":"linear","zero":false}}}}]}],"title":"","config":{"legend":{}},"$schema":"https://vega.github.io/schema/vega-lite/v5.json","encoding":{}}""")

"""Junaid Akram's channel is the oldest followed by Lex Fridman. The newest one is Vaad.

### Who published the most videos?
"""

DeepnoteChart(general_stats, """{"layer":[{"layer":[{"mark":{"clip":true,"type":"bar","color":"#4c78a8","tooltip":true},"encoding":{"x":{"sort":null,"type":"nominal","field":"Channel_name","scale":{"type":"linear"}},"y":{"sort":null,"type":"quantitative","field":"Total_Videos","scale":{"type":"linear"},"format":{"type":"default","decimals":null},"aggregate":"sum","formatType":"numberFormatFromNumberType"}}}]}],"title":"","config":{"legend":{}},"$schema":"https://vega.github.io/schema/vega-lite/v5.json","encoding":{}}""")

"""Needed to remove ANI news because that's an outlier now substituted with Andrew Huberman

### Let’s give our video_df data frame some attention now.
"""

video_df.describe()

"""Let's compare the avg number of views with avg number of likes.

479140 - views and 13715 - likes. Impressive

### Let’s check out the Top 10 Viewed videos across all channels:
"""

def top_ten_views(df):
    ordered  = df.sort_values('Views', ascending = False)
    top_ten = ordered.head(10)
    plt.xticks(rotation=90)
    plot = sns.barplot(y=top_ten['Views'] , x=top_ten['Title'], palette ='Blues_r').set_xticklabels(labels = top_ten['Title'])
    plot;

top_ten_views(video_df)

"""### Let’s now check the Top 10 videos viewed but based on a specific channel:"""

def top_10_viewed_each_channel(df, name):
    name_df = df[df.Identity == name]
    ordered = name_df.sort_values('Views', ascending=False)
    top_10 = ordered.head(10)
    plt.xticks(rotation=90)
    plot = sns.barplot(y=top_10['Views'] , x=top_10['Title'], palette ='Blues_r').set_xticklabels(labels = top_10['Title'])
    plot;

top_10_viewed_each_channel(video_df,'BeerBiceps')

general_stats.to_csv('general.csv')
video_df.to_csv('videos.csv')

"""<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6c505d26-d5e3-4eb6-a79f-e2795ea697a4' target="_blank">
<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>
Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>
"""